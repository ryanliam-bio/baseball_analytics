{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanliam-bio/baseball_analytics/blob/main/SABR4_Module_10_Stuff%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SABR Certification Course 4: Module 10 - Stuff and Stuff+\n",
        "\n",
        "Congrats on completing 90% of the course. You only have the hard part left!\n",
        "\n",
        "## Stuff and Stuff+\n",
        "\n",
        "We're used to thinking about pitchers with good \"stuff\" and bad \"stuff\" referring to the inherent quality of their pitches. But how do you measure that? Well, thanks to the wonders of PitchF/X and now Statcast, we can do so.\n",
        "\n",
        "In brief, what we'll be doing is running two _multivariate regression models_ to measure the quality of each player's pitches. As the outcome variable, we'll use the linear weight value of what happened on the pitch (so did it get knocked out of park, was it a strike, did the hitter bat into a 6-4-3, etc.). As predictors, we'll use the inherent, measured characteristics of each pitch, like the velocity, release angle, and spin.\n",
        "\n",
        "I'll ask you to build a known Stuff model first. I want you to use a Random Forest and build the model based solely on a few predictor variables (see below for details). This is to check that you understand the basics of statistical modeling. We'll call this our **Stuff model**.\n",
        "\n",
        "Next, I want you to build a second statistical model that is an improvement on the Stuff model. We'll call this our **Stuff+ model**. You can do this any way you'd like; you can include more variables, you can try a better model type, you can try preprocessing the data or something else. The idea here is to get creative and to see how much you can push the performance of the model--just like we did with MARCEL."
      ],
      "metadata": {
        "id": "J1VMGZ97jZrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The assignment\n",
        "\n",
        "You may have noticed that this is going to be very similar to the last class, except instead of building a MARCEL model, you're going to build a Stuff+ model. Why this progression? Well, MARCEL is fundamentally an algebra equation. Beating it, for most students, involves doing a bit of programming, but often little or no statistical work--you can easily tweak constants to build a better MARCEL. This time, Stuff+ _requires_ statistics and some understanding of what to do.\n",
        "\n",
        "I'll give you a dataset to train your models on, with known run value numbers. Then, I'll give you a second dataset to predict on, without the run value numbers.\n",
        "\n",
        "There are two models I'd like you to fit.\n",
        "1. First, I'll ask you to build a Random Forest model (using the ranger R package) that incorporates the following variables:\n",
        "- pitch type, velocity at release, horizontal and vertical break, horizontal and vertical location at the plate, the home team (for the stadium information), and the handedness of the batter\n",
        "- These correspond to the following variables in the file:\n",
        "_pitch_type, release_speed, pfx_x, pfx_z, plate_x, plate_z, home_team, stand_\n",
        "2. Next, build a model that _outperforms_ the basic Random Forest model. You can do this a lot of different ways: using another kind of model, using other predictor variables, hyperparameter tuning, incorporating external data, etc., etc. Please be mindful of _overfitting_, because you will not be able to train on the testing data. You have to make predictions on it without knowing the true run value.\n",
        "\n",
        "The training data for the assignment is here:\n",
        "\n",
        "https://huggingface.co/spaces/rkarthur/sabr4evaluation/resolve/main/data/training_data.csv?download=true\n",
        "\n",
        "And the testing data is here:\n",
        "https://huggingface.co/spaces/rkarthur/sabr4evaluation/resolve/main/data/test_data_for_testing.csv?download=true\n",
        "\n",
        "Just like last time, I'll ask you for a brief, 1-2 paragraph explanation of your improved Stuff+ model. In a few words, how did you do it? You can also address what you tried, what worked and what didn't, and perhaps how you approached the assignment. This section is there because it's extremely important to be able to explain your work--without explaining how you got the answer you got, others won't be able to trust your results.\n",
        "\n"
      ],
      "metadata": {
        "id": "WOs6SqwUjlwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Web App\n",
        "\n",
        "You can find the Streamlit app [here](https://huggingface.co/spaces/rkarthur/sabr4evaluation). It functions very similarly to the one we used last time. The only difference is that we'll be submitting \"stuff\" columns instead of MARCEL columns.\n",
        "\n",
        "As in the last course, you'll need to enter your name and email before making a submission. And again, the grader will check for two specific columns; in this case, one labeled \"Stuff\" and another labeled \"StuffPlus\".\n",
        "\n",
        "https://huggingface.co/spaces/rkarthur/sabr4evaluation"
      ],
      "metadata": {
        "id": "KIl8oa40Mp9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Reminder About AI\n",
        "\n",
        "AI tools such as Claude or chatGPT have become increasingly useful in programming and technical work in general. I am not against using these tools in the assignment. But there's a key point I want to make about _how_ you use them.\n",
        "\n",
        "AI tools should be used as tutors, **not** as workers. Why? A few reasons:\n",
        "1) AI tools are unreliable. Always check what they say against independent sources. If you start to suspect some kind of hallucination, Google it! (Or use another search engine, since Google is itself now largely AI-powered.)\n",
        "2) If you don't understand what the AI is telling you, you are shortchanging yourself. The main benefit of this class is what you learn. If you don't learn to do the work and have the AI do it, you'll lose the value of the class.\n",
        "\n"
      ],
      "metadata": {
        "id": "mFFGs6FCKK9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Good luck!"
      ],
      "metadata": {
        "id": "XgYUlOEl3Phx"
      }
    }
  ]
}